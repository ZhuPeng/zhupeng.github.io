---
layout: post
title: GitHub 开源项目 yl4579/StyleTTS2 介绍，StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models
tags: Python
---

大家好，又见面了，我是 GitHub 精选君！

今天要给大家推荐一个 GitHub 开源项目 yl4579/StyleTTS2，该项目在 GitHub 有超过 2.7k Star，用一句话介绍该项目就是：“StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion and Adversarial Training with Large Speech Language Models”。





背景介绍：
如果你曾遇到需要将文字转化为语音，比如智能语音助手、音频书籍、语音指南等场景，那么你一定知道制作高质量、自然和接近人的语音是多么困难。在 Text-to-Speech (TTS) 技术中，需要克服的主要挑战是生成准确的概念风格和自然的语音旋律。 StyleTTS 2 是一个公开的、解决以上问题的项目。

项目介绍：
StyleTTS 2 是一个文本到语音（TTS）模型，通过结合风格扩散和大型语言模型的对抗性训练来实现接近人类的 TTS 合成。与其前代 StyleTTS 不同，StyleTTS 2 通过扩散模型将风格建模为潜在随机变量，无需参考语音即可生成文本最合适的风格，达到了高效的潜在扩散，并借助扩散模型提供的丰富语音合成。此外，我们使用如 WavLM 等大型预训练语音语言模型（SLM）作为判别器，配合创新的可微分持续时间建模进行端到端的训练，从而提升语音的自然度。

如何使用：
首先，需要 Python 3.7 或更高版本并克隆此存储库：
```bash
git clone https://github.com/yl4579/StyleTTS2.git
cd StyleTTS2
```
然后，安装 Python 需求项：
```bash
pip install -r requirements.txt
```
如果你想运行演示，还需要安装 phonemizer 和 espeak：
```bash
pip install phonemizer
sudo apt-get install espeak-ng
```
项目还需下载并提取 [LJSpeech 数据集](https://keithito.com/LJ-Speech-Dataset/)，解压到数据文件夹并将数据上采样为 24 kHz。

项目推介：
StyleTTS 2 已在单发声器 LJSpeech 数据集上超越了人类录音，并在多发声器 VCTK 数据集上与人类录音相匹配，得到了以英语为母语的人的评价。此外，当在 LibriTTS 数据集上训练时，我们的模型在零点对讲者适应上优于以前公开可用的模型。对于开发者和研究人员来说，这个项目中的源代码和模型都是人类级别 TTS 合成的重要资源，且对风格扩散和大型 SLM 的利用显示了其潜力。项目的论文已在 [论文链接](https://arxiv.org/abs/2306.07691) 发布，你也可以在 [音频样本](https://styletts2.github.io/) 查看或听到项目的实际运用效果。


以下是该项目 Star 趋势图（代表项目的活跃程度）：

![](https://api.star-history.com/svg?repos=yl4579/StyleTTS2&type=Timeline)

更多项目详情请查看如下链接。

开源项目地址：https://github.com/yl4579/StyleTTS2 

开源项目作者：yl4579

以下是参与项目建设的所有成员：

![](https://contrib.rocks/image?repo=yl4579/StyleTTS2)

关注我们，一起探索有意思的开源项目。

